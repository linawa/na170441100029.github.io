## KNN SKLEARN, K-NEAREST NEIGHBOR MENGGUNAKAN SCIKIT LEARN DENGAN BREAST CANCER DATA SET

Implementasi knn classifier di scikit belajar Dalam pengantar k tetangga terdekat dan penerapan pengklasifikasi knn di Python dari awal, Kami membahas aspek-aspek kunci dari algoritma knn dan mengimplementasikan algoritma knn dengan cara yang mudah untuk beberapa dataset pengamatan.

Namun dalam implementasiK-Neighbor di scikit learn, kita akan memeriksa Dataset **Cancer Breast** menggunakan library python sklearn untuk memodelkan algoritma k-nn. Setelah memodelkan knn classifier, kita akan menggunakan model knn tranining untuk memprediksi apakah pasien menderita tumor jinak atau tumor ganas. Kehebatan menggunakan Sklearn adalah memberikan kita fungsionalitas untuk mengimplementasikan algoritma *machine learning* dalam beberapa baris kode.

Ketika kita membahas prinsip di balik algoritma KNN classifier (K-Nearest Neighbor) adalah untuk menemukan jumlah training sampel K yang telah ditentukan terdekat dalam jarak ke titik baru & memprediksi label dari ini. Ukuran jarak umumnya dianggap sebagai jarak Euclidean.

[Euclidean Distance](1) adalah ukuran jarak yang paling umum digunakan. Jarak Euclidean juga disebut sebagai jarak semata. Penggunaan ukuran jarak Euclidean sangat dianjurkan saat data padat atau kontinu. Jarak Euclidean adalah ukuran kedekatan terbaik. Jarak Euclidean antara dua titik adalah panjang jalur yang menghubungkannya. Teorema Pythagoras memberikan jarak ini antara dua titik.

#### Implementasi knn dengan Sklearn

##### **Wisconsin Breast Cancer Dataset**

 Wisconsin Breast Cancer Dataset dikumpulkan oleh Dr. William H. Wolberg (dokter), Rumah Sakit Universitas Wisconsin, AS. Dataset ini terdiri dari 10 atribut kontinu dan 1 atribut kelas target. Atribut Class menunjukkan hasil pengamatan, apakah pasien menderita tumor jinak atau tumor ganas. Tumor jinak tidak menyebar ke bagian lain sementara tumor ganas bersifat kanker. Dataset dikumpulkan & didistribusikan secara terbuka untuk mengetahui beberapa pola dari data ini.

Atribut Class menunjukkan hasil pengamatan, apakah pasien menderita tumor jinak atau tumor ganas. Tumor jinak tidak menyebar ke bagian lain sementara tumor ganas bersifat kanker. Dataset dikumpulkan & didistribusikan secara terbuka untuk mengetahui beberapa pola dari data ini.



#### Breast Cancer Data Set Attribute Information:

1. Sample code number: id number
2. Clump Thickness: 1 – 10
3. Uniformity of Cell Size: 1 – 10
4. Uniformity of Cell Shape: 1 – 10
5. Marginal Adhesion: 1 – 10
6. Single Epithelial Cell Size: 1 – 10
7. Bare Nuclei: 1 – 10
8. Bland Chromatin: 1 – 10
9. Normal Nucleoli: 1 – 10
10. Mitoses: 1 – 10
11. Class: (2 for benign, 4 for malignant)

#### Pernyataan masalah:

Untuk memodelkan pengklasifikasi knn menggunakan Breast Cancer Dataset  untuk memprediksi apakah pasien menderita tumor jinak atau tumor ganas.

#### Model KNN untuk deteksi tumor kanker:

Untuk mendiagnosis Kanker Payudara, dokter menggunakan pengalamannya dengan menganalisis rincian yang diberikan oleh

- Riwayat Medis Masa Lalu Pasien
- Laporan semua tes dilakukan.

Menggunakan classifier KNN yang dimodelkan, kami akan memecahkan masalah dengan cara yang mirip dengan prosedur yang digunakan oleh dokter. Classifier KNN yang dimodelkan akan membandingkan laporan uji pasien baru, metrik observasi dengan catatan pasien (data pelatihan) yang diklasifikasikan dengan benar sebagai jinak atau ganas.



## K-nearest neighbor classifier implementation with scikit-learn

Libraries :

Bagian ini melibatkan mengimpor semua library. saya mengimpor numpy dan sklearn, train_test_split, KneighborsClassifier & akurasi_score.



```python
import numpy as np
from sklearn.preprocessing import Imputer
from sklearn.cross_validation import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
```

saya menggunakan Breast Cancer Dataset. Anda dapat mengunduhnya dari situs web [archive.ics.uci.edu.](2) Untuk mengimpor data dan memanipulasinya, saya menggunakan array numpy.
Menggunakan metode `genfromtxt ()`, kami mengimpor dataset kami ke dalam array 2d numpy. Anda dapat mengimpor file teks menggunakan fungsi ini. saya menggunakan 3 parameter:

> - **fname** Ini menangani nama file dengan ekstensi.
> - **delimiter** String yang digunakan untuk memisahkan nilai. Dalam dataset kami “,” (koma) adalah pemisah.
> - **dtype **Ini menangani tipe data variabel.



Semua nilai bersifat numerik dalam basis data saya. Tetapi beberapa nilai hilang dan digantikan oleh "?". Jadi, harus melakukan imputasi data. Karena alasan ini, saya menggunakan tipe float.

```python
cancer_data = np.genfromtxt(
 fname ='breast-cancer-wisconsin.data', delimiter= ',', dtype= float)
```

Dengan menggunakan kode di atas, kami telah mengimpor data kami ke array 2d numpy.

> **len ()**: Berfungsi untuk mencari tahu no. catatan dalam data kami.
> **str ()**: Berfungsi untuk mendapatkan ide tentang struktur dasar data.
> **shape()**: Untuk mendapatkan dimensi array.

```python
print "Dataset Lenght:: ", len(cancer_data)
print "Dataset:: ", str(cancer_data)
print "Dataset Shape:: ", cancer_data.shape
```

**output:**

```python
Dataset Length:: 699

Dataset::
[[  1.00002500e+06   5.00000000e+00   1.00000000e+00 ...,   1.00000000e+00
    1.00000000e+00   2.00000000e+00]
 [  1.00294500e+06   5.00000000e+00   4.00000000e+00 ...,   2.00000000e+00
    1.00000000e+00   2.00000000e+00]
 [  1.01542500e+06   3.00000000e+00   1.00000000e+00 ...,   1.00000000e+00
    1.00000000e+00   2.00000000e+00]
 ..., 
 [  8.88820000e+05   5.00000000e+00   1.00000000e+01 ...,   1.00000000e+01
    2.00000000e+00   4.00000000e+00]
 [  8.97471000e+05   4.00000000e+00   8.00000000e+00 ...,   6.00000000e+00
    1.00000000e+00   4.00000000e+00]
 [  8.97471000e+05   4.00000000e+00   8.00000000e+00 ...,   4.00000000e+00
    1.00000000e+00   4.00000000e+00]]

Dataset Shape:: (699L, 11L)
```

Kolom dataset pertama kanker terdiri dari id pasien. Untuk membuat proses prediksi ini tidak bias, kita harus menghapus id pasien ini. Kita dapat menggunakan metode numpy delete () untuk operasi ini.

**delete ():** Ini mengembalikan array yang diubah baru. Tiga parameter harus dilewati.

> **arr**: Ini memegang nama array.
> **obj**: Ini menunjukkan sub-array mana yang akan dihapus.
> **axis**: Sumbu tempat untuk menghapus. sumbu = 1 digunakan untuk kolom & sumbu = 0 untuk baris.

```python
cancer_data = np.delete(arr = cancer_data, obj= 0, axis = 1)
```

Sekarang, kami ingin membagi dataset menjadi dataset fitur & label. yaitu, data fitur adalah variabel prediktor, mereka akan membantu kami untuk memprediksi label (variabel kriteria). Di sini, 9 kolom pertama termasuk variabel kontinu yang akan membantu kita untuk memprediksi apakah seorang pasien mengalami tumor jinak atau tumor ganas.

```python
X = cancer_data[:,range(0,9)]
Y = cancer_data[:,9]
```



#### Data Imputation:

Imputasi adalah proses penggantian nilai yang hilang dengan nilai yang diganti. Dalam dataset kami, beberapa kolom memiliki nilai yang hilang. Kita dapat mengganti nilai yang hilang dengan nilai tengah, median, mode atau nilai tertentu apa pun.
Sklearn menyediakan metode Imputer () untuk melakukan imputasi dalam 1 baris kode. Kita hanya perlu mendefinisikan missing_values, sumbu, dan strategi. Kami menggunakan nilai "median" kolom untuk menggantikan dengan nilai yang hilang.

imp = Imputer (missing_values = "NaN", strategy = 'median', axis = 0)
X = imp.fit_transform (X)



```python
imp = Imputer(missing_values="NaN", strategy='median', axis=0)
X = imp.fit_transform(X)
```



#### Train, Test data split:

Untuk membagi data menjadi data train& data uji. Kami menggunakan metode train_test_split () oleh sklearn.
**train_test_split ()**: Kami menggunakan 4 parameter X, Y, test_size, random_state



> - **X, Y**           : X adalah array numpy yang terdiri dari dataset fitur & Y berisi label untuk setiap record.
> - **test_size** : Ini mewakili ukuran data uji yang perlu dipisah. Jika kita menggunakan 0,4, itu menunjukkan 40% data harus dipisahkan dan disimpan sebagai data pengujian.
> - **random_state** : Keadaan pseudo-random number generator yang digunakan untuk pengambilan sampel acak. Jika Anda ingin mereplikasi hasil kami, maka gunakan nilai random_state yang sama.



Sekarang, X_train & y_train adalah dataset training. X_test & y_test sedang menguji dataset.
y_train & y_test adalah array numpy 2d dengan 1 kolom. Untuk mengubahnya menjadi array 1d, saya menggunakan ravel ().

```python
X_train, X_test, y_train, y_test = train_test_split(
 X, Y, test_size = 0.3, random_state = 100)
y_train = y_train.ravel()
y_test = y_test.ravel()
```



#### Implementasi k-nn :

Sekarang saya menyesuaikan algoritma KNN pada data train, memprediksi label untuk dataset dan mencetak akurasi model untuk nilai K yang berbeda (mulai dari 1 hingga 25).

Jika array data fitur dimasukkan sebagai parameter, maka array label diberikan sebagai output



**Accuracy score:**

**Accuracy_score():** Fungsi ini digunakan untuk mencetak akurasi algoritma KNN. Secara akurat, maksud kami adalah rasio titik data yang diprediksi dengan benar dengan semua titik data yang diprediksi. Akurasi sebagai metrik membantu memahami efektivitas algoritme kami. Dibutuhkan 4 parameter.

- y_true,
- y_pred,
- normalize,
- sample_weight.

Dari 4 ini, normalisasi & sample_weight adalah parameter opsional. Parameter y_true menerima larik label yang benar dan y_pred mengambil larik label yang diprediksi yang dikembalikan oleh classifier. Ini mengembalikan akurasi sebagai nilai float.

```python
for K in range(25):
 K_value = K+1
 neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')
 neigh.fit(X_train, y_train) 
 y_pred = neigh.predict(X_test)
 print "Accuracy is ", accuracy_score(y_test,y_pred)*100,"% for K-Value:",K_value

```

**Output** : 

```python
Accuracy is  95.2380952381 % for K-Value: 1
Accuracy is  93.3333333333 % for K-Value: 2
Accuracy is  95.7142857143 % for K-Value: 3
Accuracy is  95.2380952381 % for K-Value: 4
Accuracy is  95.7142857143 % for K-Value: 5
Accuracy is  94.7619047619 % for K-Value: 6
Accuracy is  94.7619047619 % for K-Value: 7
Accuracy is  94.2857142857 % for K-Value: 8
Accuracy is  94.7619047619 % for K-Value: 9
Accuracy is  94.2857142857 % for K-Value: 10
Accuracy is  94.2857142857 % for K-Value: 11
Accuracy is  94.7619047619 % for K-Value: 12
Accuracy is  94.7619047619 % for K-Value: 13
Accuracy is  93.8095238095 % for K-Value: 14
Accuracy is  93.8095238095 % for K-Value: 15
Accuracy is  93.8095238095 % for K-Value: 16
Accuracy is  93.8095238095 % for K-Value: 17
Accuracy is  93.8095238095 % for K-Value: 18
Accuracy is  93.8095238095 % for K-Value: 19
Accuracy is  93.8095238095 % for K-Value: 20
Accuracy is  93.8095238095 % for K-Value: 21
Accuracy is  93.8095238095 % for K-Value: 22
Accuracy is  93.8095238095 % for K-Value: 23
Accuracy is  93.8095238095 % for K-Value: 24
Accuracy is  93.8095238095 % for K-Value: 25

```

### K value Vs Accuracy Change Graph

![](C:\Users\PERSONALISE NOTEBOOK\Pictures\knn.PNG)



Ini menunjukkan bahwa kita mendapatkan akurasi 95,71% pada K = 3, 5. Memilih nilai besar K akan menyebabkan jumlah waktu eksekusi yang lebih besar & kekurangan. Memilih nilai kecil K akan menyebabkan overfitting. Tidak ada cara yang dijamin untuk menemukan nilai terbaik dari K. Jadi, untuk menjalankannya dengan cepat, kami mempertimbangkan K = 3 untuk tutorial ini.



my instagram : [@linajosalinka](3)

my e-mail : linalinawa07@gmail.com

